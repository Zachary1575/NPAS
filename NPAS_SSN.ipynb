{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fde6fd-9556-4b9f-9b04-62e01204c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys, shutil, time, random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plummer Other Lib Imports\n",
    "import copy\n",
    "import argparse\n",
    "import warnings\n",
    "import contextlib\n",
    "from __future__ import division # Dunno what this does\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b33ec6-db45-43dc-9154-0e9c6c65c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plummer Imports for Images and Statistical ML\n",
    "import PIL\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d27103d-36dd-4e53-a97f-1b5684e79951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch Stuff\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Plummer Torch Imports\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Local Imports\n",
    "#import models # Unsure what this is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d72d2b-f78e-4e93-8ac3-8870b7311551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow Stuff\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7673da6-2204-49e8-a2a2-05ae9d01ff10",
   "metadata": {},
   "source": [
    "# Citation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c828e963-2e08-4dd6-9ecd-780551e37e01",
   "metadata": {},
   "source": [
    "```\n",
    "@InProceedings{\n",
    "    plummerNPAS2022,\n",
    "    author={ Bryan A. Plummer and Nikoli Dryden and Julius Frost and Torsten Hoefler and Kate Saenko },\n",
    "    title={Neural Parameter Allocation Search},\n",
    "    booktitle={International Conference on Learning Representations (ICLR)},\n",
    "    year={2022}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ca0ce-78ad-4f0c-8f60-83d0cb1d1160",
   "metadata": {},
   "source": [
    "# Utility (from util.py imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a83cc88-08c9-4416-bf5d-90a599363c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cutout(object):\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.n_holes):\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask\n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "# Lighting data augmentation take from here - https://github.com/eladhoffer/convNet.pytorch/blob/master/preprocess.py\n",
    "class Lighting(object):\n",
    "    \"\"\"Lighting noise(AlexNet - style PCA - based noise)\"\"\"\n",
    "\n",
    "    def __init__(self, alphastd, eigval, eigvec):\n",
    "        self.alphastd = alphastd\n",
    "        self.eigval = eigval\n",
    "        self.eigvec = eigvec\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if self.alphastd == 0:\n",
    "            return img\n",
    "\n",
    "        alpha = img.new().resize_(3).normal_(0, self.alphastd)\n",
    "        rgb = self.eigvec.type_as(img).clone()\\\n",
    "            .mul(alpha.view(1, 3).expand(3, 3))\\\n",
    "            .mul(self.eigval.view(1, 3).expand(3, 3))\\\n",
    "            .sum(1).squeeze()\n",
    "        return img.add(rgb.view(3, 1, 1).expand_as(img))\n",
    "\n",
    "\n",
    "# Adapted from https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/Classification/ConvNets/image_classification/smoothing.py\n",
    "class LabelSmoothingNLLLoss(torch.nn.Module):\n",
    "    \"\"\"NLL loss with label smoothing.\"\"\"\n",
    "\n",
    "    def __init__(self, smoothing=0.0):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.confidence = 1.0 - smoothing\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n",
    "        nll_loss = (-logprobs.gather(dim=-1, index=target.unsqueeze(1))).squeeze(1)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = self.confidence*nll_loss + self.smoothing*smooth_loss\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "class RandomDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset that just returns a random tensor for debugging.\"\"\"\n",
    "\n",
    "    def __init__(self, sample_shape, dataset_size, label=True, pil=False,\n",
    "                 transform=None):\n",
    "        super().__init__()\n",
    "        self.sample_shape = sample_shape\n",
    "        self.dataset_size = dataset_size\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        if pil:\n",
    "            d = torch.rand(sample_shape)\n",
    "            self.d = torchvision.transforms.functional.to_pil_image(d)\n",
    "        else:\n",
    "            self.d = torch.rand(sample_shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        d = self.d\n",
    "        if self.transform is not None:\n",
    "            d = self.transform(d)\n",
    "        if self.label:\n",
    "            return d, 0\n",
    "        else:\n",
    "            return d\n",
    "\n",
    "\n",
    "# Adapted from https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/Classification/ConvNets/image_classification/dataloaders.py#L250\n",
    "class PrefetchWrapper:\n",
    "    \"\"\"Fetch ahead and do some asynchronous processing.\"\"\"\n",
    "\n",
    "    def __init__(self, data_loader, mean, stdev, lighting):\n",
    "        self.data_loader = data_loader\n",
    "        self.mean = mean\n",
    "        self.stdev = stdev\n",
    "        self.lighting = lighting\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.sampler = data_loader.sampler  # To simplify set_epoch.\n",
    "\n",
    "    def prefetch_loader(data_loader, mean, stdev, lighting, stream):\n",
    "        if lighting is not None:\n",
    "            mean = torch.tensor(mean).cuda().view(1, 3, 1, 1)\n",
    "            stdev = torch.tensor(stdev).cuda().view(1, 3, 1, 1)\n",
    "        else:\n",
    "            mean = torch.tensor([x*255 for x in mean]).cuda().view(1, 3, 1, 1)\n",
    "            stdev = torch.tensor([x*255 for x in stdev]).cuda().view(1, 3, 1, 1)\n",
    "\n",
    "        first = True\n",
    "        for next_input, next_target in data_loader:\n",
    "            with torch.cuda.stream(stream):\n",
    "                next_target = next_target.cuda(non_blocking=True)\n",
    "                next_input = next_input.cuda(non_blocking=True).float()\n",
    "                if lighting is not None:\n",
    "                    # Scale and apply lighting first.\n",
    "                    next_input = next_input.div_(255.0)\n",
    "                    next_input = lighting(next_input).sub_(mean).div_(stdev)\n",
    "                else:\n",
    "                    next_input = next_input.sub_(mean).div_(stdev)\n",
    "\n",
    "            if not first:\n",
    "                yield input, target\n",
    "            else:\n",
    "                first = False\n",
    "\n",
    "            torch.cuda.current_stream().wait_stream(stream)\n",
    "            input = next_input\n",
    "            target = next_target\n",
    "        yield input, target\n",
    "\n",
    "    def __iter__(self):\n",
    "        return PrefetchWrapper.prefetch_loader(\n",
    "            self.data_loader, self.mean, self.stdev, self.lighting, self.stream)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)\n",
    "\n",
    "\n",
    "def fast_collate(batch):\n",
    "    imgs = [img[0] for img in batch]\n",
    "    targets = torch.tensor([target[1] for target in batch], dtype=torch.int64)\n",
    "    w = imgs[0].size[0]\n",
    "    h = imgs[0].size[1]\n",
    "    tensor = torch.zeros((len(imgs), 3, h, w), dtype=torch.uint8)\n",
    "    for i, img in enumerate(imgs):\n",
    "        nump_array = np.asarray(img, dtype=np.uint8)\n",
    "        if nump_array.ndim < 3:\n",
    "            nump_array = np.expand_dims(nump_array, axis=-1)\n",
    "        nump_array = np.rollaxis(nump_array, 2)\n",
    "        # Suppress warnings.\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            tensor[i] += torch.from_numpy(nump_array)\n",
    "    return tensor, targets\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "  \"\"\"Computes and stores the average and current value\"\"\"\n",
    "  def __init__(self):\n",
    "    self.reset()\n",
    "\n",
    "  def reset(self):\n",
    "    self.val = 0\n",
    "    self.avg = 0\n",
    "    self.sum = 0\n",
    "    self.count = 0\n",
    "\n",
    "  def update(self, val, n=1):\n",
    "    self.val = val\n",
    "    self.sum += val * n\n",
    "    self.count += n\n",
    "    self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class RecorderMeter(object):\n",
    "  \"\"\"Computes and stores the minimum loss value and its epoch index\"\"\"\n",
    "  def __init__(self, total_epoch):\n",
    "    self.reset(total_epoch)\n",
    "\n",
    "  def reset(self, total_epoch):\n",
    "    assert total_epoch > 0\n",
    "    self.total_epoch   = total_epoch\n",
    "    self.current_epoch = 0\n",
    "    self.epoch_losses  = np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n",
    "    self.epoch_losses  = self.epoch_losses - 1\n",
    "\n",
    "    self.epoch_accuracy= np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n",
    "    self.epoch_accuracy= self.epoch_accuracy\n",
    "\n",
    "  def refresh(self, epochs):\n",
    "    if epochs == self.total_epoch: return\n",
    "    self.epoch_losses = np.vstack( (self.epoch_losses, np.zeros((epochs - self.total_epoch, 2), dtype=np.float32) - 1) )\n",
    "    self.epoch_accuracy = np.vstack( (self.epoch_accuracy, np.zeros((epochs - self.total_epoch, 2), dtype=np.float32)) )\n",
    "    self.total_epoch = epochs\n",
    "\n",
    "  def update(self, idx, train_loss, train_acc, val_loss, val_acc):\n",
    "    assert idx >= 0 and idx < self.total_epoch, 'total_epoch : {} , but update with the {} index'.format(self.total_epoch, idx)\n",
    "    self.epoch_losses  [idx, 0] = train_loss\n",
    "    self.epoch_losses  [idx, 1] = val_loss\n",
    "    self.epoch_accuracy[idx, 0] = train_acc\n",
    "    self.epoch_accuracy[idx, 1] = val_acc\n",
    "    self.current_epoch = idx + 1\n",
    "    return self.max_accuracy(False) == val_acc\n",
    "\n",
    "  def max_accuracy(self, istrain):\n",
    "    if self.current_epoch <= 0: return 0\n",
    "    if istrain: return self.epoch_accuracy[:self.current_epoch, 0].max()\n",
    "    else:       return self.epoch_accuracy[:self.current_epoch, 1].max()\n",
    "\n",
    "  def plot_curve(self, save_path):\n",
    "    title = 'the accuracy/loss curve of train/val'\n",
    "    dpi = 80\n",
    "    width, height = 1200, 800\n",
    "    legend_fontsize = 10\n",
    "    scale_distance = 48.8\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    x_axis = np.array([i for i in range(self.total_epoch)]) # epochs\n",
    "    y_axis = np.zeros(self.total_epoch)\n",
    "\n",
    "    plt.xlim(0, self.total_epoch)\n",
    "    plt.ylim(0, 100)\n",
    "    interval_y = 5\n",
    "    interval_x = 5\n",
    "    plt.xticks(np.arange(0, self.total_epoch + interval_x, interval_x))\n",
    "    plt.yticks(np.arange(0, 100 + interval_y, interval_y))\n",
    "    plt.grid()\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.xlabel('the training epoch', fontsize=16)\n",
    "    plt.ylabel('accuracy', fontsize=16)\n",
    "\n",
    "    y_axis[:] = self.epoch_accuracy[:, 0]\n",
    "    plt.plot(x_axis, y_axis, color='g', linestyle='-', label='train-accuracy', lw=2)\n",
    "    plt.legend(loc=4, fontsize=legend_fontsize)\n",
    "\n",
    "    y_axis[:] = self.epoch_accuracy[:, 1]\n",
    "    plt.plot(x_axis, y_axis, color='y', linestyle='-', label='valid-accuracy', lw=2)\n",
    "    plt.legend(loc=4, fontsize=legend_fontsize)\n",
    "\n",
    "\n",
    "    y_axis[:] = self.epoch_losses[:, 0]\n",
    "    plt.plot(x_axis, y_axis*50, color='g', linestyle=':', label='train-loss-x50', lw=2)\n",
    "    plt.legend(loc=4, fontsize=legend_fontsize)\n",
    "\n",
    "    y_axis[:] = self.epoch_losses[:, 1]\n",
    "    plt.plot(x_axis, y_axis*50, color='y', linestyle=':', label='valid-loss-x50', lw=2)\n",
    "    plt.legend(loc=4, fontsize=legend_fontsize)\n",
    "\n",
    "    if save_path is not None:\n",
    "      fig.savefig(save_path, dpi=dpi, bbox_inches='tight')\n",
    "      print ('---- save figure {} into {}'.format(title, save_path))\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def time_string():\n",
    "    ISOTIMEFORMAT = '%Y-%m-%d %X'\n",
    "    string = '[{}]'.format(time.strftime(\n",
    "        ISOTIMEFORMAT, time.gmtime(time.time())))\n",
    "    return string\n",
    "\n",
    "\n",
    "def convert_secs2time(epoch_time):\n",
    "    need_hour = int(epoch_time / 3600)\n",
    "    need_mins = int((epoch_time - 3600*need_hour) / 60)\n",
    "    need_secs = int(epoch_time - 3600*need_hour - 60*need_mins)\n",
    "    return need_hour, need_mins, need_secs\n",
    "\n",
    "\n",
    "def time_file_str():\n",
    "    ISOTIMEFORMAT = '%Y-%m-%d'\n",
    "    string = '{}'.format(time.strftime(\n",
    "        ISOTIMEFORMAT, time.gmtime(time.time())))\n",
    "    return string + '-{}'.format(random.randint(1, 10000))\n",
    "\n",
    "\n",
    "# Utilities for distributed training.\n",
    "\n",
    "def get_num_gpus():\n",
    "    \"\"\"Number of GPUs on this node.\"\"\"\n",
    "    return torch.cuda.device_count()\n",
    "\n",
    "\n",
    "def get_local_rank():\n",
    "    \"\"\"Get local rank from environment.\"\"\"\n",
    "    if 'MV2_COMM_WORLD_LOCAL_RANK' in os.environ:\n",
    "        return int(os.environ['MV2_COMM_WORLD_LOCAL_RANK'])\n",
    "    elif 'OMPI_COMM_WORLD_LOCAL_RANK' in os.environ:\n",
    "        return int(os.environ['OMPI_COMM_WORLD_LOCAL_RANK'])\n",
    "    elif 'SLURM_LOCALID' in os.environ:\n",
    "        return int(os.environ['SLURM_LOCALID'])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def get_local_size():\n",
    "    \"\"\"Get local size from environment.\"\"\"\n",
    "    if 'MV2_COMM_WORLD_LOCAL_SIZE' in os.environ:\n",
    "        return int(os.environ['MV2_COMM_WORLD_LOCAL_SIZE'])\n",
    "    elif 'OMPI_COMM_WORLD_LOCAL_SIZE' in os.environ:\n",
    "        return int(os.environ['OMPI_COMM_WORLD_LOCAL_SIZE'])\n",
    "    elif 'SLURM_NTASKS_PER_NODE' in os.environ:\n",
    "        return int(os.environ['SLURM_NTASKS_PER_NODE'])\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def get_world_rank():\n",
    "    \"\"\"Get rank in world from environment.\"\"\" \n",
    "    if 'MV2_COMM_WORLD_RANK' in os.environ:\n",
    "        return int(os.environ['MV2_COMM_WORLD_RANK'])\n",
    "    elif 'OMPI_COMM_WORLD_RANK' in os.environ:\n",
    "        return int(os.environ['OMPI_COMM_WORLD_RANK'])\n",
    "    elif 'SLURM_PROCID' in os.environ:\n",
    "        return int(os.environ['SLURM_PROCID'])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def get_world_size():\n",
    "    \"\"\"Get world size from environment.\"\"\"\n",
    "    if 'MV2_COMM_WORLD_SIZE' in os.environ:\n",
    "        return int(os.environ['MV2_COMM_WORLD_SIZE'])\n",
    "    elif 'OMPI_COMM_WORLD_SIZE' in os.environ:\n",
    "        return int(os.environ['OMPI_COMM_WORLD_SIZE'])\n",
    "    elif 'SLURM_NTASKS' in os.environ:\n",
    "        return int(os.environ['SLURM_NTASKS'])\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def initialize_dist(init_file):\n",
    "    \"\"\"Initialize PyTorch distributed backend.\"\"\"\n",
    "    torch.cuda.init()\n",
    "    torch.cuda.set_device(get_local_rank())\n",
    "    init_file = os.path.abspath(init_file)\n",
    "    torch.distributed.init_process_group(\n",
    "        backend='nccl', init_method=f'file://{init_file}',\n",
    "        rank=get_world_rank(), world_size=get_world_size()\n",
    "    )\n",
    "    torch.distributed.barrier()\n",
    "    # Ensure the init file is removed.\n",
    "    if get_world_rank() == 0 and os.path.exists(init_file):\n",
    "        os.unlink(init_file)\n",
    "\n",
    "def get_cuda_device():\n",
    "    \"\"\"Get this rank's CUDA device.\"\"\"\n",
    "    return torch.device(f'cuda:{get_local_rank()}')\n",
    "\n",
    "\n",
    "def allreduce_tensor(t):\n",
    "    \"\"\"Allreduce and average tensor t.\"\"\"\n",
    "    rt = t.clone().detach()\n",
    "    torch.distributed.all_reduce(rt)\n",
    "    rt /= get_world_size()\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dc8af3-c650-457a-b490-4e27b03c197f",
   "metadata": {},
   "source": [
    "# Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84011ef9-605c-4adf-bc05-1ac46cc3040e",
   "metadata": {},
   "source": [
    "Christ, this is very long. I think the preprocessing is included as well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50c84d2-8e2a-478c-b756-4003cc5616a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    if args.dataset == 'cifar10':\n",
    "        mean, std = [x / 255 for x in [125.3, 123.0, 113.9]],  [x / 255 for x in [63.0, 62.1, 66.7]] \n",
    "        dataset = dset.CIFAR10\n",
    "        num_classes = 10\n",
    "    elif args.dataset == 'cifar100':\n",
    "        mean, std = [x / 255 for x in [129.3, 124.1, 112.4]], [x / 255 for x in [68.2, 65.4, 70.4]]\n",
    "        dataset = dset.CIFAR100\n",
    "        num_classes = 100\n",
    "    elif args.dataset not in ['imagenet', 'rand_imagenet']:\n",
    "        assert False, \"Unknown dataset : {}\".format(args.dataset) # so I assume we cannot use a custom dataset?\n",
    "\n",
    "    if args.dataset == 'cifar10' or args.dataset == 'cifar100':\n",
    "        #train_transform = transforms.Compose([transforms.Scale(256), transforms.RandomHorizontalFlip(), transforms.RandomCrop(224), transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "        train_transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "        if args.cutout: train_transform.transforms.append(Cutout(n_holes=1, length=16))\n",
    "        #test_transform = transforms.Compose([transforms.Scale(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "        test_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "\n",
    "        # Ensure only one rank downloads\n",
    "        if args.dist and get_world_rank() != 0:\n",
    "            torch.distributed.barrier()\n",
    "\n",
    "        if args.evaluate:\n",
    "            train_data = dataset(args.data_path, train=True,\n",
    "                                 transform=train_transform, download=True)\n",
    "            test_data = dataset(args.data_path, train=False,\n",
    "                                transform=test_transform, download=True)\n",
    "\n",
    "            train_loader = torch.utils.data.DataLoader(\n",
    "                train_data, batch_size=args.batch_size, shuffle=True,\n",
    "                num_workers=args.workers, pin_memory=True)\n",
    "            test_loader = torch.utils.data.DataLoader(\n",
    "                test_data, batch_size=args.batch_size, shuffle=False,\n",
    "                num_workers=args.workers, pin_memory=True)\n",
    "        else:\n",
    "            # partition training set into two instead.\n",
    "            # note that test_data is defined using train=True\n",
    "            train_data = dataset(args.data_path, train=True,\n",
    "                                 transform=train_transform, download=True)\n",
    "            test_data = dataset(args.data_path, train=True,\n",
    "                                transform=test_transform, download=True)\n",
    "\n",
    "            indices = list(range(len(train_data)))\n",
    "            np.random.shuffle(indices)\n",
    "            split = int(0.9 * len(train_data))\n",
    "            train_indices, test_indices = indices[:split], indices[split:]\n",
    "            if args.dist:\n",
    "                # Use the distributed sampler here.\n",
    "                train_subset = torch.utils.data.Subset(\n",
    "                    train_data, train_indices)\n",
    "                train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "                    train_subset, num_replicas=get_world_size(),\n",
    "                    rank=get_world_rank())\n",
    "                train_loader = torch.utils.data.DataLoader(\n",
    "                    train_subset, batch_size=args.batch_size,\n",
    "                    sampler=train_sampler, num_workers=args.workers,\n",
    "                    pin_memory=True)\n",
    "                test_subset = torch.utils.data.Subset(test_data, test_indices)\n",
    "                test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "                    test_subset, num_replicas=get_world_size(),\n",
    "                    rank=get_world_rank())\n",
    "                test_loader = torch.utils.data.DataLoader(\n",
    "                    test_subset, batch_size=args.batch_size,\n",
    "                    sampler=test_sampler, num_workers=args.workers,\n",
    "                    pin_memory=True)\n",
    "            else:\n",
    "                train_sampler = SubsetRandomSampler(train_indices)\n",
    "                train_loader = torch.utils.data.DataLoader(\n",
    "                    train_data, batch_size=args.batch_size,\n",
    "                    num_workers=args.workers, pin_memory=True,\n",
    "                    sampler=train_sampler)\n",
    "                test_sampler = SubsetRandomSampler(test_indices)\n",
    "                test_loader = torch.utils.data.DataLoader(\n",
    "                    test_data, batch_size=args.batch_size,\n",
    "                    num_workers=args.workers, pin_memory=True,\n",
    "                    sampler=test_sampler)\n",
    "\n",
    "        # Let ranks through.\n",
    "        if args.dist and get_world_rank() == 0:\n",
    "            torch.distributed.barrier()\n",
    "\n",
    "    elif args.dataset == 'imagenet':\n",
    "        if args.dist:\n",
    "            imagenet_means = [0.485, 0.456, 0.406]\n",
    "            imagenet_stdevs = [0.229, 0.224, 0.225]\n",
    "\n",
    "            # Can just read off SSDs.\n",
    "            if 'efficientnet' in args.arch:\n",
    "                image_size = models.efficientnet.EfficientNet.get_image_size(\n",
    "                    args.effnet_arch)\n",
    "                train_transform = transforms.Compose([\n",
    "                    models.efficientnet.augmentations.Augmentation(\n",
    "                        models.efficientnet.augmentations.get_fastautoaugment_policy()),\n",
    "                    models.efficientnet.augmentations.EfficientNetRandomCrop(\n",
    "                        image_size),\n",
    "                    transforms.Resize((image_size, image_size),\n",
    "                                      PIL.Image.BICUBIC),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ColorJitter(0.4, 0.4, 0.4),\n",
    "                ])\n",
    "                test_transform = transforms.Compose([\n",
    "                    models.efficientnet.augmentations.EfficientNetCenterCrop(\n",
    "                        image_size),\n",
    "                    transforms.Resize((image_size, image_size),\n",
    "                                      PIL.Image.BICUBIC)\n",
    "                ])\n",
    "            else:\n",
    "                # Transforms adapted from imagenet_seq's, except that color jitter\n",
    "                # and lighting are not applied in random orders, and that resizing\n",
    "                # is done with bilinear instead of cubic interpolation.\n",
    "                train_transform = transforms.Compose([\n",
    "                    transforms.RandomResizedCrop((224, 224)),\n",
    "                    # transforms.ColorJitter(0.4, 0.4, 0.4),\n",
    "                    transforms.RandomHorizontalFlip()])\n",
    "                test_transform = transforms.Compose([\n",
    "                    transforms.Resize(256),\n",
    "                    transforms.CenterCrop((224, 224))])\n",
    "            train_data = dset.ImageFolder(\n",
    "                args.data_path + '/train', transform=train_transform)\n",
    "            test_data = dset.ImageFolder(\n",
    "                args.data_path + '/val', transform=test_transform)\n",
    "            train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "                train_data, num_replicas=get_world_size(),\n",
    "                rank=get_world_rank())\n",
    "            train_loader = torch.utils.data.DataLoader(\n",
    "                train_data, batch_size=args.batch_size, sampler=train_sampler,\n",
    "                num_workers=args.workers, pin_memory=True,\n",
    "                collate_fn=fast_collate, drop_last=args.drop_last)\n",
    "            train_loader = PrefetchWrapper(\n",
    "                train_loader, imagenet_means, imagenet_stdevs,\n",
    "                Lighting(0.1,\n",
    "                         torch.Tensor([0.2175, 0.0188, 0.0045]).cuda(),\n",
    "                         torch.Tensor([\n",
    "                             [-0.5675, 0.7192, 0.4009],\n",
    "                             [-0.5808, -0.0045, -0.8140],\n",
    "                             [-0.5836, -0.6948, 0.4203],\n",
    "                         ]).cuda()))\n",
    "            test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "                test_data, num_replicas=get_world_size(),\n",
    "                rank=get_world_rank())\n",
    "            test_loader = torch.utils.data.DataLoader(\n",
    "                test_data, batch_size=args.batch_size, sampler=test_sampler,\n",
    "                num_workers=args.workers, pin_memory=True,\n",
    "                collate_fn=fast_collate)\n",
    "            test_loader = PrefetchWrapper(\n",
    "                test_loader, imagenet_means, imagenet_stdevs, None)\n",
    "        else:\n",
    "            import imagenet_seq\n",
    "            train_loader = imagenet_seq.data.Loader(\n",
    "                'train', batch_size=args.batch_size, num_workers=args.workers)\n",
    "            test_loader = imagenet_seq.data.Loader(\n",
    "                'val', batch_size=args.batch_size, num_workers=args.workers)\n",
    "        num_classes = 1000\n",
    "    elif args.dataset == 'rand_imagenet':\n",
    "        imagenet_means = [0.485, 0.456, 0.406]\n",
    "        imagenet_stdevs = [0.229, 0.224, 0.225]\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop((224, 224)),\n",
    "            transforms.ColorJitter(0.4, 0.4, 0.4),\n",
    "            transforms.RandomHorizontalFlip()])\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224)])\n",
    "        train_data = RandomDataset((3, 256, 256), 1200000, pil=True,\n",
    "                                   transform=train_transform)\n",
    "        test_data = RandomDataset((3, 256, 256), 50000, pil=True,\n",
    "                                  transform=test_transform)\n",
    "        if args.dist:\n",
    "            train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "                train_data, num_replicas=get_world_size(),\n",
    "                rank=get_world_rank())\n",
    "            test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "                test_data, num_replicas=get_world_size(),\n",
    "                rank=get_world_rank())\n",
    "        else:\n",
    "            train_sampler = RandomSampler(train_data)\n",
    "            test_sampler = RandomSampler(test_data)\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_data, batch_size=args.batch_size, num_workers=args.workers,\n",
    "            pin_memory=True, sampler=train_sampler, collate_fn=fast_collate)\n",
    "        train_loader = PrefetchWrapper(\n",
    "            train_loader, imagenet_means, imagenet_stdevs,\n",
    "            Lighting(0.1,\n",
    "                     torch.Tensor([0.2175, 0.0188, 0.0045]).cuda(),\n",
    "                     torch.Tensor([\n",
    "                         [-0.5675, 0.7192, 0.4009],\n",
    "                         [-0.5808, -0.0045, -0.8140],\n",
    "                         [-0.5836, -0.6948, 0.4203],\n",
    "                     ]).cuda()))\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_data, batch_size=args.batch_size, num_workers=args.workers,\n",
    "            pin_memory=True, sampler=test_sampler, collate_fn=fast_collate)\n",
    "        test_loader = PrefetchWrapper(\n",
    "            test_loader, imagenet_means, imagenet_stdevs, None)\n",
    "        num_classes = 1000\n",
    "    else:\n",
    "        assert False, 'Do not support dataset : {}'.format(args.dataset)\n",
    "\n",
    "    return num_classes, train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f96ee-5261-4975-a26c-93d68b3f91a0",
   "metadata": {},
   "source": [
    "# Some Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f383ca0-e7e5-457d-8a8a-f1640ad11a1a",
   "metadata": {},
   "source": [
    "**Neural Parameter Allocation Search (NPAS)**: Given a neural network architecture with layers\n",
    "$l_1, . . . ,l_L$, which each require weights $w_1, . . . , w_L$, and a fixed parameter budget $\\theta$, train a\n",
    "high-performing neural network using the given architecture and parameter budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57282ac-5583-4a58-ac27-798b2aa61df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78bb00d5-03f0-4806-8e0f-1c42f2b91809",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3665d279-6bbe-4bb0-baf9-97aa51faf5f3",
   "metadata": {},
   "source": [
    "NPAS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c473b1a-1ef6-48ed-9ff6-cb9e305d0b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(\n",
    "    num_classes, \n",
    "    log, \n",
    "    max_params, \n",
    "    share_type, \n",
    "    upsample_type,\n",
    "    groups=None\n",
    "):\n",
    "    print_log(\"=> creating model '{}'\".format(args.arch), log)\n",
    "    \n",
    "    if args.arch == 'efficientnet_imagenet':\n",
    "        net = models.efficientnet_imagenet(\n",
    "            args.effnet_arch, share_type, upsample_type, args.upsample_window,\n",
    "            args.bank_size, max_params, groups\n",
    "        )\n",
    "    else:\n",
    "        net = models.__dict__[args.arch](\n",
    "            share_type, upsample_type, args.upsample_window, args.depth,\n",
    "            args.wide, args.bank_size, max_params, num_classes, groups\n",
    "        )\n",
    "    \n",
    "    print_log(\"=> network :\\n {}\".format(net), log)\n",
    "    if args.dist:\n",
    "        net = net.to(get_cuda_device())\n",
    "    else:\n",
    "        net = torch.nn.DataParallel(\n",
    "            net.cuda(), device_ids=list(range(args.ngpu)))\n",
    "    trainable_params = filter(lambda p: p.requires_grad, net.parameters())\n",
    "    params = sum([p.numel() for p in trainable_params])\n",
    "    print_log(\"Number of parameters: {}\".format(params), log)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c751f2d8-8ca1-4b06-bd86-32d8827ee4c7",
   "metadata": {},
   "source": [
    "# Main Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac43b2d-f6ba-467f-9edd-40e7f603dbbf",
   "metadata": {},
   "source": [
    "Lots of lots of code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5aca3b-34e2-4632-8f0b-d09221447933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global best_acc, best_los # Why global?\n",
    "\n",
    "    if get_world_rank() == 0: \n",
    "        if not os.path.isdir(args.save_path):\n",
    "            os.makedirs(args.save_path)\n",
    "        log = open(os.path.join(\n",
    "            args.save_path, 'log_seed_{}.txt'.format(args.manualSeed)), 'w')\n",
    "    else:\n",
    "        log = None\n",
    "    print_log('save path : {}'.format(args.save_path), log)\n",
    "    state = {k: v for k, v in args._get_kwargs()}\n",
    "    print_log(state, log)\n",
    "    print_log(\"Random Seed: {}\".format(args.manualSeed), log)\n",
    "    print_log(\"Python version : {}\".format(sys.version.replace('\\n', ' ')), log)\n",
    "    print_log(\"PyTorch  version : {}\".format(torch.__version__), log)\n",
    "    print_log(\"CuDNN  version : {}\".format(torch.backends.cudnn.version()), log)\n",
    "    print_log(f'Ranks: {get_world_size()}', log)\n",
    "    print_log(f'Global batch size: {args.batch_size*get_world_size()}', log)\n",
    "    \n",
    "    if get_world_rank() == 0 and not os.path.isdir(args.data_path):\n",
    "        os.makedirs(args.data_path)\n",
    "\n",
    "    num_classes, train_loader, test_loader = load_dataset() # Load the Dataset\n",
    "    \n",
    "    groups = args.param_groups\n",
    "    if args.param_groups > 1:\n",
    "        fn = os.path.join(args.save_path, 'groups.npy')\n",
    "        if args.evaluate or args.resume:\n",
    "            groups = np.load(fn)\n",
    "            assert len(set(groups)) == args.param_groups\n",
    "        else:\n",
    "            groups = get_parameter_groups(train_loader, state, num_classes, log)\n",
    "            if args.param_group_type != 'reload' and get_world_rank() == 0:\n",
    "                np.save(fn, groups)\n",
    "            if args.param_group_type == 'learned':\n",
    "                print_log('Must restart after learning parameter groups', log)\n",
    "                return\n",
    "            if args.param_group_type == 'random':\n",
    "                # Need to load this from rank 0 to get consistent view.\n",
    "                torch.distributed.barrier()\n",
    "                if get_world_rank() != 0:\n",
    "                    groups = np.load(fn)\n",
    "        print_log('groups- ' + ', '.join(\n",
    "            [str(i) + ':' + str(g) for i, g in enumerate(groups)]), log)\n",
    "\n",
    "    net = load_model(num_classes, log, args.max_params, args.share_type,\n",
    "                     args.upsample_type, groups=groups)\n",
    "\n",
    "    if args.label_smoothing > 0.0:\n",
    "        criterion = LabelSmoothingNLLLoss(args.label_smoothing)\n",
    "    else:\n",
    "        criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    decay_skip = ['coefficients']\n",
    "    if args.no_bn_decay:\n",
    "        decay_skip.append('bn')\n",
    "    params = group_weight_decay(net, state['decay'], decay_skip)\n",
    "    if args.optimizer == 'sgd':\n",
    "        if args.dist:\n",
    "            optimizer = apex.optimizers.FusedSGD(\n",
    "                params, state['learning_rate'], momentum=state['momentum'],\n",
    "                nesterov=(not args.no_nesterov and state['momentum'] > 0.0))\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(\n",
    "                params, state['learning_rate'], momentum=state['momentum'],\n",
    "                nesterov=(not args.no_nesterov and state['momentum'] > 0.0))\n",
    "    else:\n",
    "        optimizer = models.efficientnet.RMSpropTF(\n",
    "            params, state['learning_rate'], alpha=0.9, eps=1e-3,\n",
    "            momentum=state['momentum'])\n",
    "\n",
    "    if args.step_size:\n",
    "        if args.schedule:\n",
    "            raise ValueError('Cannot combine regular and step schedules')\n",
    "        step_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "           optimizer, args.step_size, args.step_gamma)\n",
    "        if args.step_warmup:\n",
    "            step_scheduler = models.efficientnet.GradualWarmupScheduler(\n",
    "                optimizer, multiplier=1.0, warmup_epoch=args.step_warmup,\n",
    "                after_scheduler=step_scheduler)\n",
    "    else:\n",
    "        step_scheduler = None\n",
    "\n",
    "    if args.dist:\n",
    "        net = torch.nn.parallel.DistributedDataParallel(\n",
    "            net,\n",
    "            device_ids=[get_local_rank()],\n",
    "            output_device=get_local_rank(),\n",
    "            find_unused_parameters=True)\n",
    "    scaler = GradScaler(enabled=args.amp)\n",
    "\n",
    "    if args.ema_decay:\n",
    "        ema_model = copy.deepcopy(net).to(get_cuda_device())\n",
    "        ema_manager = models.efficientnet.EMA(args.ema_decay)\n",
    "    else:\n",
    "        ema_model, ema_manager = None, None\n",
    "\n",
    "    recorder = RecorderMeter(args.epochs)\n",
    "    if args.resume:\n",
    "        if args.resume == 'auto':\n",
    "            args.resume = os.path.join(args.save_path, 'checkpoint.pth.tar')\n",
    "        if os.path.isfile(args.resume):\n",
    "            print_log(\"=> loading checkpoint '{}'\".format(args.resume), log)\n",
    "            checkpoint = torch.load(\n",
    "                args.resume,\n",
    "                map_location=get_cuda_device() if args.ngpu else 'cpu')\n",
    "            recorder = checkpoint['recorder']\n",
    "            recorder.refresh(args.epochs)\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            # Hack to load models that were wrapped in (D)DP.\n",
    "            if args.no_dp:\n",
    "                net = torch.nn.DataParallel(net, device_ids=[get_local_rank()])\n",
    "            net.load_state_dict(checkpoint['state_dict'])\n",
    "            if args.no_dp:\n",
    "                net = net.module\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            if step_scheduler:\n",
    "                step_scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "            if ema_manager is not None:\n",
    "                ema_manager.shadow = checkpoint['ema']\n",
    "            if args.amp:\n",
    "                scaler.load_state_dict(checkpoint['amp'])\n",
    "            best_acc = recorder.max_accuracy(False)\n",
    "            print_log(\n",
    "                \"=> loaded checkpoint '{}' accuracy={} (epoch {})\" .format(\n",
    "                    args.resume, best_acc, checkpoint['epoch']), log)\n",
    "        else:\n",
    "            print_log(\n",
    "                \"=> no checkpoint found at '{}'\".format(args.resume), log)\n",
    "    else:\n",
    "        print_log(\n",
    "            \"=> do not use any checkpoint for {} model\".format(args.arch), log)\n",
    "\n",
    "    if args.evaluate:\n",
    "        if get_world_size() > 1:\n",
    "            raise RuntimeError('Do not validate with distributed training')\n",
    "        validate(test_loader, net, criterion, log)\n",
    "        return\n",
    "\n",
    "    start_time = time.time()\n",
    "    epoch_time = AverageMeter()\n",
    "    train_los = -1\n",
    "\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        if step_scheduler:\n",
    "            current_learning_rate = step_scheduler.get_last_lr()[0]\n",
    "        else:\n",
    "            current_learning_rate = adjust_learning_rate(optimizer, epoch, args.gammas, args.schedule, train_los)\n",
    "\n",
    "        need_hour, need_mins, need_secs = convert_secs2time(epoch_time.avg * (args.epochs-epoch))\n",
    "        need_time = '[Need: {:02d}:{:02d}:{:02d}]'.format(need_hour, need_mins, need_secs)\n",
    "\n",
    "        print_log('\\n==>>{:s} [Epoch={:03d}/{:03d}] {:s} [learning_rate={:6.4f}]'.format(time_string(), epoch, args.epochs, need_time, current_learning_rate) \\\n",
    "                    + ' [Best : Accuracy={:.2f}, Error={:.2f}]'.format(recorder.max_accuracy(False), 100-recorder.max_accuracy(False)), log)\n",
    "\n",
    "        if args.dist:\n",
    "            train_loader.sampler.set_epoch(epoch)\n",
    "            test_loader.sampler.set_epoch(epoch)\n",
    "        train_acc, train_los = train(train_loader, net, criterion, optimizer,\n",
    "                                     scaler, epoch, log, step_scheduler,\n",
    "                                     ema_manager)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        val_acc, val_los = validate(test_loader, net, criterion, log,\n",
    "                                    ema_model, ema_manager)\n",
    "        recorder.update(epoch, train_los, train_acc, val_los, val_acc)\n",
    "\n",
    "        is_best = False\n",
    "        if args.best_loss:\n",
    "            if val_los < best_los:\n",
    "                is_best = True\n",
    "                best_los = val_los\n",
    "        else:\n",
    "            if val_acc > best_acc:\n",
    "                is_best = True\n",
    "                best_acc = val_acc\n",
    "\n",
    "        if get_world_rank() == 0:\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'arch': args.arch,\n",
    "                'state_dict': net.state_dict(),\n",
    "                'recorder': recorder,\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'scheduler': step_scheduler.state_dict() if step_scheduler else None,\n",
    "                'ema': ema_manager.state_dict() if ema_manager is not None else None,\n",
    "                'amp': scaler.state_dict() if args.amp else None\n",
    "            }, is_best, args.save_path, 'checkpoint.pth.tar')\n",
    "\n",
    "        epoch_time.update(time.time() - start_time)\n",
    "        start_time = time.time()\n",
    "\n",
    "        if get_world_rank() == 0:\n",
    "            recorder.plot_curve(result_png_path)\n",
    "\n",
    "    if get_world_rank() == 0:\n",
    "        log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45757f4e-bcec-4c71-a1c5-d9f7463d4f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8d7c24-0b22-47c5-9005-1b945c7b01a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8f93a3-8828-4eb2-8161-7f2d79c9aadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b1e6b3-d111-4092-993a-862db2f96bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545beba6-ca22-48a2-8594-225d0d99fac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd40f555-d0c4-4f06-b1a3-17ab3b9e2ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6904cb0-a142-414f-bab0-b31b80e746ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
